import time
import json
import pandas as pd
from textblob import TextBlob
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By

# ==============================================================================
# M√ìDULO DE INGENIER√çA DE DATOS: EXTRACCI√ìN Y AN√ÅLISIS
# ------------------------------------------------------------------------------
# Este m√≥dulo gestiona la interacci√≥n automatizada con fuentes de datos externas.
# Utiliza un motor de navegaci√≥n controlado (Selenium WebDriver) para garantizar
# la correcta interpretaci√≥n de sitios web din√°micos (SPA - Single Page Applications)
# y asegurar la obtenci√≥n fidedigna de m√©tricas de mercado en tiempo real.
# ==============================================================================

def iniciar_navegador_controlado():
    """
    Configura e inicializa una instancia del navegador Chrome para la extracci√≥n de datos.
    
    Se aplican configuraciones espec√≠ficas para:
    1. Maximizar el √°rea de visualizaci√≥n (Viewport).
    2. Asegurar compatibilidad con entornos de ejecuci√≥n modernos (MacOS/Linux/Windows).
    3. Limpiar indicadores de automatizaci√≥n para obtener una experiencia de usuario est√°ndar.
    
    Returns:
        webdriver.Chrome: Instancia activa del navegador lista para operar.
        None: Si ocurre un error cr√≠tico durante la inicializaci√≥n.
    """
    print("   üîß [Sistema] Inicializando motor de navegaci√≥n (Chrome WebDriver)...")
    
    options = Options()
    options.add_argument("--start-maximized")
    
    # --- CONFIGURACI√ìN DE ESTABILIDAD Y COMPATIBILIDAD ---
    # Estas banderas son necesarias para que Chrome opere fluidamente en entornos
    # con gesti√≥n de memoria restrictiva o sin entorno gr√°fico (aunque aqu√≠ usamos GUI).
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    
    # --- NORMALIZACI√ìN DEL ENTORNO ---
    # Eliminamos banderas que alteran el comportamiento est√°ndar del navegador
    # para asegurar que la p√°gina se renderice tal como la ver√≠a un usuario final.
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    
    try:
        # Selenium 4+ gestiona autom√°ticamente los drivers binarios necesarios.
        driver = webdriver.Chrome(options=options)
        return driver
    except Exception as e:
        print(f"   ‚ùå [Error Cr√≠tico] No se pudo iniciar el entorno de navegaci√≥n: {e}")
        return None

def ejecutar_solicitud_json(driver, url):
    """
    Realiza una navegaci√≥n a la URL especificada y extrae el payload de datos (JSON)
    renderizado en el cuerpo del documento.

    Args:
        driver (webdriver): La instancia activa del navegador.
        url (str): El endpoint o direcci√≥n web a consultar.

    Returns:
        dict: Datos parseados en formato diccionario si la extracci√≥n es exitosa.
        None: Si ocurre un error de red o de parseo.
    """
    print(f"   ü§ñ [Solicitud] Navegando a endpoint: {url}")
    try:
        driver.get(url)
        
        # TIEMPO DE ESPERA DE RENDERIZADO (WAIT TIME)
        # Pausa t√©cnica de 3 segundos para permitir la carga as√≠ncrona de recursos
        # y asegurar que el DOM est√© completamente disponible antes de leer.
        time.sleep(3) 
        
        # Extracci√≥n del contenido textual del elemento <body>
        content = driver.find_element(By.TAG_NAME, "body").text
        return json.loads(content)
    except Exception as e:
        print(f"   ‚ö†Ô∏è [Excepci√≥n] Fallo en la lectura de datos: {e}")
        return None

# ==============================================================================
# L√ìGICA DE EXTRACCI√ìN DE TENDENCIAS (DATA SOURCING)
# ==============================================================================

def obtener_tendencias_mercado(limit=10):
    """
    Consulta la fuente de datos de tendencias para identificar los t√©rminos
    de mayor inter√©s actual en el mercado (High Intent Keywords).

    Args:
        limit (int): Cantidad m√°xima de tendencias a retornar.

    Returns:
        pd.DataFrame: Tabla con las palabras clave y sus metadatos.
    """
    url = "https://api.mercadolibre.com/trends/MLA"
    
    print("üîÑ [Proceso] Iniciando sesi√≥n de extracci√≥n de Tendencias...")
    driver = iniciar_navegador_controlado()
    
    if not driver: 
        return pd.DataFrame() # Retorno vac√≠o ante fallo de infraestructura

    try:
        data = ejecutar_solicitud_json(driver, url)
        if data:
            print(f"   ‚úÖ [√âxito] Dataset descargado: {len(data)} registros encontrados.")
            return pd.DataFrame(data).head(limit)
        else:
            print("   ‚ö†Ô∏è [Alerta] La fuente de datos no devolvi√≥ registros.")
            return pd.DataFrame()
    except Exception as e:
        print(f"   ‚ùå [Error] Excepci√≥n no controlada en tendencias: {e}")
        return pd.DataFrame()
    finally:
        # GESTI√ìN DE RECURSOS:
        # Es imperativo cerrar la sesi√≥n del navegador para liberar memoria RAM y CPU.
        if driver:
            print("   üèÅ [Sistema] Finalizando sesi√≥n de navegador.")
            driver.quit() 

# ==============================================================================
# L√ìGICA DE AN√ÅLISIS DE NICHO (MARKET INTELLIGENCE)
# ==============================================================================

def analizar_nicho_mercado(keyword):
    """
    Ejecuta un an√°lisis profundo sobre una palabra clave espec√≠fica.
    Cruza datos cuantitativos (Oferta) con cualitativos (Sentimiento).

    Args:
        keyword (str): El t√©rmino de b√∫squeda a investigar.

    Returns:
        dict: Objeto con m√©tricas consolidadas (Precio, Competencia, Sentimiento).
        None: Si no es posible obtener datos suficientes.
    """
    # Instanciamos un nuevo contexto de navegador para asegurar una sesi√≥n limpia (Stateless)
    driver = iniciar_navegador_controlado()
    if not driver: return None
    
    datos_consolidados = None
    
    try:
        # --- FASE 1: An√°lisis Cuantitativo de la Oferta ---
        url_search = f"https://api.mercadolibre.com/sites/MLA/search?q={keyword}"
        data = ejecutar_solicitud_json(driver, url_search)
        
        if data:
            results = data.get('results', [])
            total_resultados = data.get('paging', {}).get('total', 0)
            
            if results:
                # C√°lculo de m√©tricas estad√≠sticas b√°sicas
                precios = [item.get('price', 0) for item in results]
                precio_promedio = sum(precios) / len(precios)
                
                # Identificaci√≥n de saturaci√≥n de mercado (Dominio de vendedores Platinum)
                platinum_count = sum(1 for item in results if item.get('seller', {}).get('seller_reputation', {}).get('power_seller_status') == 'platinum')
                pct_platinum = (platinum_count / len(results)) * 100
                
                # --- FASE 2: An√°lisis Cualitativo (Voz del Cliente) ---
                # Identificamos al l√≠der de la categor√≠a para auditar su feedback
                top_item_id = results[0].get('id')
                url_questions = f"https://api.mercadolibre.com/questions/search?item_id={top_item_id}"
                data_questions = ejecutar_solicitud_json(driver, url_questions)
                
                preguntas_texto = []
                if data_questions:
                    preguntas_texto = [q.get('text', '') for q in data_questions.get('questions', [])]
                
                # Procesamiento de Lenguaje Natural (Sentiment Analysis)
                score_sent = 0
                label_sent = "Neutro"
                if preguntas_texto:
                    scores = [TextBlob(t).sentiment.polarity for t in preguntas_texto]
                    score_sent = sum(scores) / len(scores)
                    
                    # Categorizaci√≥n del resultado num√©rico
                    if score_sent > 0.1: label_sent = "Positivo"
                    elif score_sent < -0.1: label_sent = "Negativo"

                # Estructuraci√≥n del objeto de datos final
                datos_consolidados = {
                    "keyword": keyword,
                    "competencia_cantidad": total_resultados,
                    "precio_promedio": round(precio_promedio, 2),
                    "porcentaje_platinum": round(pct_platinum, 1),
                    "sentimiento_score": round(score_sent, 2),
                    "sentimiento_label": label_sent,
                    "cant_preguntas_analizadas": len(preguntas_texto)
                }
                
    except Exception as e:
        print(f"   ‚ùå Error durante el an√°lisis de '{keyword}': {e}")
    finally:
        if driver:
            driver.quit()
        
    return datos_consolidados

# ==============================================================================
# L√ìGICA PRINCIPAL DE PROCESAMIENTO (PIPELINE)
# ==============================================================================

def generar_reporte_oportunidades():
    """
    Punto de entrada principal. Ejecuta el flujo completo de inteligencia de negocios:
    1. Identificaci√≥n de Oportunidades (Tendencias).
    2. Enriquecimiento de Datos (An√°lisis Competitivo).
    3. C√°lculo de Scoring (Algoritmo de Oportunidad).
    
    Returns:
        pd.DataFrame: Reporte final estructurado listo para visualizaci√≥n.
    """
    # Definimos el alcance del an√°lisis (Limitado a 3 para eficiencia en demostraciones)
    df_trends = obtener_tendencias_mercado(limit=3) 
    
    # Validaci√≥n de integridad de datos
    if df_trends.empty:
        print("   ‚ö†Ô∏è [Aviso] No hay datos de tendencias para procesar.")
        return pd.DataFrame()

    resultados_procesados = []
    print("‚è≥ [Pipeline] Iniciando procesamiento secuencial de nichos...")
    
    for index, row in df_trends.iterrows():
        keyword = row['keyword']
        print(f"   üîé [Analizando Nicho] {keyword}...")
        
        # Ejecuci√≥n del an√°lisis profundo
        datos = analizar_nicho_mercado(keyword)
        
        if datos:
            datos['ranking_tendencia'] = index + 1
            resultados_procesados.append(datos)
        
    df_final = pd.DataFrame(resultados_procesados)
    
    # Algoritmo de Scoring de Oportunidad (Opportunity Index)
    if not df_final.empty:
        # F√≥rmula: Prioriza nichos con alta demanda pero baja saturaci√≥n de competidores fuertes.
        # (Evitamos divisi√≥n por cero sumando 1 al denominador)
        df_final['opportunity_score'] = (
            (1 / (df_final['competencia_cantidad'] + 1)) * (100 - df_final['porcentaje_platinum']) * 10000
        ).round(2)
    
    return df_final
